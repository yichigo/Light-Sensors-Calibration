{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "related-recovery",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import boto\n",
    "import os\n",
    "import time\n",
    "#suppress deprecation warnings\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", category=DeprecationWarning)\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import boto3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "liberal-directory",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "########################################################################################################\n",
    "# Function to conpare the difference in two lists\n",
    "def Diff(li1, li2):\n",
    "    li_dif = [i for i in li1 + li2 if i not in li1]\n",
    "    return li_dif\n",
    "\n",
    "# Get all sites' name\n",
    "def get_allsites():\n",
    "    all_sites = []\n",
    "    locs = pyart.io.nexrad_common.NEXRAD_LOCATIONS\n",
    "    for key in locs:\n",
    "        all_sites.append(key)\n",
    "    return all_sites\n",
    "\n",
    "########################################################################################################\n",
    "def customized_download(date='2020/05/16',all_sites=['KFWS']):\n",
    "\n",
    "    #create a datetime object for the current time in UTC and use the\n",
    "    # year, month, and day to drill down into the NEXRAD directory structure.\n",
    "    #date = (\"{:4d}\".format(now.year) + '/' + \"{:02d}\".format(now.month) + '/' +\n",
    "    #        \"{:2d}\".format(now.day) + '/')\n",
    "\n",
    "\n",
    "    print(\"Search Date %s\" %(date))\n",
    "\n",
    "    awscount = 0\n",
    "    Fail_lst =[]\n",
    "    awslst = []\n",
    "    #get the bucket list for the selected date\n",
    "\n",
    "    #use boto to connect to the AWS nexrad holdings directory\n",
    "    s3conn = boto.connect_s3()\n",
    "    bucket = s3conn.get_bucket('noaa-nexrad-level2')\n",
    "    s3 = boto3.resource('s3')\n",
    "\n",
    "    #Note: this returns a list of all of the radar sites with data for\n",
    "    # the selected date\n",
    "    ls = bucket.list(prefix=date + '/',delimiter='/')\n",
    "    for item in ls:\n",
    "        awslst.append(item.name.split('/')[-2])\n",
    "\n",
    "    #Find the Missing sites from AWS lst at the select date\n",
    "    li3 = Diff(awslst, all_sites)\n",
    "    print(\"Missing sites : %s \" %(li3))\n",
    "    \n",
    "    for key in ls:\n",
    "#         print(key.name)\n",
    "        awscount+=1\n",
    "    print(\"%d sites are selected, total %d sites returned from AWS at %s %s\" %(len(all_sites),awscount-1,date,time))\n",
    "    print(\"===================================================================================\")\n",
    "    print('\\n')\n",
    "\n",
    "    for site in all_sites:\n",
    "        for key in ls:\n",
    "            #only pull the data and save the arrays for the site we want\n",
    "            if site in key.name.split('/')[-2]:\n",
    "                print(\"%s has been found in AWS return list \" %(site))\n",
    "                #set up the path to the NEXRAD files\n",
    "                path = date +'/' + site + '/' + site\n",
    "\n",
    "                keys = bucket.get_all_keys(prefix=path)\n",
    "                \n",
    "                n = 1\n",
    "                for s3key in keys:\n",
    "                    try: \n",
    "                        dir_out = '/Volumes/Backup Plus/NEXRAD/data'\n",
    "                        print(\"Downloading %s (%d/%d)\" %(s3key.name,n,len(keys)))\n",
    "                        Path(os.path.join(dir_out, date.replace(\"/\",\"-\"))).mkdir(parents = True, exist_ok=True)\n",
    "                        s3.Bucket('noaa-nexrad-level2').download_file(s3key.name, os.path.join(dir_out, date.replace(\"/\",\"-\"), s3key.name.replace(\"/\",\"_\")))\n",
    "                        n += 1\n",
    "                    except:\n",
    "                        print(\"%s not read sucsseful <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\" %(s3key.name))\n",
    "                        Fail_lst.append(s3key.name)\n",
    "                        print('\\n')\n",
    "                        \n",
    "        print(\"Failed reading sites %s\" %(Fail_lst))\n",
    "        \n",
    "        \n",
    "        \n",
    "#####################################################################################################\n",
    "def daterange(date1, date2):\n",
    "    for n in range(int ((date2 - date1).days)+1):\n",
    "        yield date1 + datetime.timedelta(n)\n",
    "\n",
    "##################################################################################################\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "first-hampton",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "# define a spacific date\n",
    "#     mydate = \"2020/06/24\"\n",
    "#     mysites = ['KFWS']\n",
    "#     customized_download(date=mydate,all_sites = mysites)\n",
    "\n",
    "\n",
    "# Define a date range\n",
    "folder = \"spatial\"\n",
    "node_id = \"10004098\"\n",
    "dir_out = \"../figures/\" + folder + \"/\"\n",
    "dir_data = \"../data/\"\n",
    "\n",
    "fn_in = dir_data + \"driving_\" + node_id + \".csv\"\n",
    "df = pd.read_csv(fn_in, parse_dates=True, index_col = 'UTC')\n",
    "\n",
    "dates = set(df.index.date)\n",
    "\n",
    "dates_prev = set(date - datetime.timedelta(days = 1) for date in set(df.index.date))\n",
    "dates_next = set(date + datetime.timedelta(days = 1) for date in set(df.index.date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consistent-alliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "mysites = ['KFWS']\n",
    "for dt in (dates| dates_prev | dates_next):\n",
    "    customized_download(date=dt.strftime(\"%Y/%m/%d\"),all_sites = mysites)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smart-mexico",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search Date 2020/01/07\n",
      "Missing sites : [] \n",
      "1 sites are selected, total 155 sites returned from AWS at 2020/01/07 <module 'time' (built-in)>\n",
      "===================================================================================\n",
      "\n",
      "\n",
      "KFWS has been found in AWS return list \n",
      "Downloading 2020/01/07/KFWS/KFWS20200107_000233_V06 (1/205)\n",
      "Downloading 2020/01/07/KFWS/KFWS20200107_001220_V06 (2/205)\n",
      "Downloading 2020/01/07/KFWS/KFWS20200107_002208_V06 (3/205)\n",
      "Downloading 2020/01/07/KFWS/KFWS20200107_003155_V06 (4/205)\n",
      "Downloading 2020/01/07/KFWS/KFWS20200107_004143_V06 (5/205)\n",
      "Downloading 2020/01/07/KFWS/KFWS20200107_005131_V06 (6/205)\n",
      "Downloading 2020/01/07/KFWS/KFWS20200107_005131_V06_MDM (7/205)\n",
      "Downloading 2020/01/07/KFWS/KFWS20200107_010118_V06 (8/205)\n",
      "Downloading 2020/01/07/KFWS/KFWS20200107_011106_V06 (9/205)\n",
      "Downloading 2020/01/07/KFWS/KFWS20200107_012053_V06 (10/205)\n",
      "Downloading 2020/01/07/KFWS/KFWS20200107_013040_V06 (11/205)\n",
      "Downloading 2020/01/07/KFWS/KFWS20200107_014027_V06 (12/205)\n",
      "Downloading 2020/01/07/KFWS/KFWS20200107_015016_V06 (13/205)\n",
      "Downloading 2020/01/07/KFWS/KFWS20200107_020004_V06 (14/205)\n",
      "Downloading 2020/01/07/KFWS/KFWS20200107_020004_V06_MDM (15/205)\n",
      "Downloading 2020/01/07/KFWS/KFWS20200107_020950_V06 (16/205)\n",
      "Downloading 2020/01/07/KFWS/KFWS20200107_021939_V06 (17/205)\n",
      "Downloading 2020/01/07/KFWS/KFWS20200107_022927_V06 (18/205)\n",
      "Downloading 2020/01/07/KFWS/KFWS20200107_023915_V06 (19/205)\n",
      "Downloading 2020/01/07/KFWS/KFWS20200107_024903_V06 (20/205)\n",
      "Downloading 2020/01/07/KFWS/KFWS20200107_024903_V06_MDM (21/205)\n",
      "Downloading 2020/01/07/KFWS/KFWS20200107_030051_V06 (22/205)\n",
      "Downloading 2020/01/07/KFWS/KFWS20200107_031038_V06 (23/205)\n",
      "Downloading 2020/01/07/KFWS/KFWS20200107_032025_V06 (24/205)\n",
      "Downloading 2020/01/07/KFWS/KFWS20200107_033014_V06 (25/205)\n",
      "Downloading 2020/01/07/KFWS/KFWS20200107_034003_V06 (26/205)\n",
      "Downloading 2020/01/07/KFWS/KFWS20200107_034952_V06 (27/205)\n",
      "Downloading 2020/01/07/KFWS/KFWS20200107_035939_V06 (28/205)\n",
      "Downloading 2020/01/07/KFWS/KFWS20200107_035939_V06_MDM (29/205)\n",
      "Downloading 2020/01/07/KFWS/KFWS20200107_040926_V06 (30/205)\n",
      "Downloading 2020/01/07/KFWS/KFWS20200107_041915_V06 (31/205)\n",
      "Downloading 2020/01/07/KFWS/KFWS20200107_042903_V06 (32/205)\n",
      "Downloading 2020/01/07/KFWS/KFWS20200107_043851_V06 (33/205)\n",
      "Downloading 2020/01/07/KFWS/KFWS20200107_044840_V06 (34/205)\n",
      "Downloading 2020/01/07/KFWS/KFWS20200107_045827_V06 (35/205)\n",
      "Downloading 2020/01/07/KFWS/KFWS20200107_045827_V06_MDM (36/205)\n",
      "Downloading 2020/01/07/KFWS/KFWS20200107_050816_V06 (37/205)\n",
      "Downloading 2020/01/07/KFWS/KFWS20200107_051804_V06 (38/205)\n",
      "Downloading 2020/01/07/KFWS/KFWS20200107_052752_V06 (39/205)\n",
      "Downloading 2020/01/07/KFWS/KFWS20200107_053740_V06 (40/205)\n",
      "Downloading 2020/01/07/KFWS/KFWS20200107_054727_V06 (41/205)\n",
      "Downloading 2020/01/07/KFWS/KFWS20200107_055715_V06 (42/205)\n",
      "Downloading 2020/01/07/KFWS/KFWS20200107_055715_V06_MDM (43/205)\n",
      "Downloading 2020/01/07/KFWS/KFWS20200107_060704_V06 (44/205)\n",
      "Downloading 2020/01/07/KFWS/KFWS20200107_061651_V06 (45/205)\n",
      "Downloading 2020/01/07/KFWS/KFWS20200107_062638_V06 (46/205)\n",
      "Downloading 2020/01/07/KFWS/KFWS20200107_063626_V06 (47/205)\n",
      "Downloading 2020/01/07/KFWS/KFWS20200107_064613_V06 (48/205)\n",
      "Downloading 2020/01/07/KFWS/KFWS20200107_065600_V06 (49/205)\n",
      "Downloading 2020/01/07/KFWS/KFWS20200107_065600_V06_MDM (50/205)\n",
      "Downloading 2020/01/07/KFWS/KFWS20200107_070547_V06 (51/205)\n",
      "Downloading 2020/01/07/KFWS/KFWS20200107_071534_V06 (52/205)\n",
      "Downloading 2020/01/07/KFWS/KFWS20200107_072522_V06 (53/205)\n",
      "Downloading 2020/01/07/KFWS/KFWS20200107_073510_V06 (54/205)\n",
      "Downloading 2020/01/07/KFWS/KFWS20200107_074458_V06 (55/205)\n",
      "Downloading 2020/01/07/KFWS/KFWS20200107_075447_V06 (56/205)\n",
      "Downloading 2020/01/07/KFWS/KFWS20200107_075447_V06_MDM (57/205)\n",
      "Downloading 2020/01/07/KFWS/KFWS20200107_080435_V06 (58/205)\n",
      "Downloading 2020/01/07/KFWS/KFWS20200107_081423_V06 (59/205)\n",
      "Downloading 2020/01/07/KFWS/KFWS20200107_082411_V06 (60/205)\n",
      "Downloading 2020/01/07/KFWS/KFWS20200107_083359_V06 (61/205)\n",
      "Downloading 2020/01/07/KFWS/KFWS20200107_084346_V06 (62/205)\n",
      "Downloading 2020/01/07/KFWS/KFWS20200107_085334_V06 (63/205)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twenty-romania",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
